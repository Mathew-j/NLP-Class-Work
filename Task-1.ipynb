{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['och',\n",
       " 'det',\n",
       " 'att',\n",
       " 'i',\n",
       " 'en',\n",
       " 'jag',\n",
       " 'hon',\n",
       " 'som',\n",
       " 'han',\n",
       " 'på',\n",
       " 'den',\n",
       " 'med',\n",
       " 'var',\n",
       " 'sig',\n",
       " 'för',\n",
       " 'så',\n",
       " 'till',\n",
       " 'är',\n",
       " 'men',\n",
       " 'ett',\n",
       " 'om',\n",
       " 'hade',\n",
       " 'de',\n",
       " 'av',\n",
       " 'icke',\n",
       " 'mig',\n",
       " 'du',\n",
       " 'henne',\n",
       " 'då',\n",
       " 'sin',\n",
       " 'nu',\n",
       " 'har',\n",
       " 'inte',\n",
       " 'hans',\n",
       " 'honom',\n",
       " 'skulle',\n",
       " 'hennes',\n",
       " 'där',\n",
       " 'min',\n",
       " 'man',\n",
       " 'ej',\n",
       " 'vid',\n",
       " 'kunde',\n",
       " 'något',\n",
       " 'från',\n",
       " 'ut',\n",
       " 'när',\n",
       " 'efter',\n",
       " 'upp',\n",
       " 'vi',\n",
       " 'dem',\n",
       " 'vara',\n",
       " 'vad',\n",
       " 'över',\n",
       " 'än',\n",
       " 'dig',\n",
       " 'kan',\n",
       " 'sina',\n",
       " 'här',\n",
       " 'ha',\n",
       " 'mot',\n",
       " 'alla',\n",
       " 'under',\n",
       " 'någon',\n",
       " 'eller',\n",
       " 'allt',\n",
       " 'mycket',\n",
       " 'sedan',\n",
       " 'ju',\n",
       " 'denna',\n",
       " 'själv',\n",
       " 'detta',\n",
       " 'åt',\n",
       " 'utan',\n",
       " 'varit',\n",
       " 'hur',\n",
       " 'ingen',\n",
       " 'mitt',\n",
       " 'ni',\n",
       " 'bli',\n",
       " 'blev',\n",
       " 'oss',\n",
       " 'din',\n",
       " 'dessa',\n",
       " 'några',\n",
       " 'deras',\n",
       " 'blir',\n",
       " 'mina',\n",
       " 'samma',\n",
       " 'vilken',\n",
       " 'er',\n",
       " 'sådan',\n",
       " 'vår',\n",
       " 'blivit',\n",
       " 'dess',\n",
       " 'inom',\n",
       " 'mellan',\n",
       " 'sådant',\n",
       " 'varför',\n",
       " 'varje',\n",
       " 'vilka',\n",
       " 'ditt',\n",
       " 'vem',\n",
       " 'vilket',\n",
       " 'sitta',\n",
       " 'sådana',\n",
       " 'vart',\n",
       " 'dina',\n",
       " 'vars',\n",
       " 'vårt',\n",
       " 'våra',\n",
       " 'ert',\n",
       " 'era',\n",
       " 'vilkas']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('swedish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries=nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[\"\"\"See what words occur near other words,which provides great insight into\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('See', 'VB'), ('what', 'WP'), ('words', 'NNS'), ('occur', 'VBP'), ('near', 'IN'), ('other', 'JJ'), ('words', 'NNS'), (',', ','), ('which', 'WDT'), ('provides', 'VBZ'), ('great', 'JJ'), ('insight', 'NN'), ('into', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    sentences=nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words=nltk.word_tokenize(sentence)\n",
    "        tagged=nltk.pos_tag(words)\n",
    "        print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'part', 'was', 'sooo', 'fun', ':D', '#superfun']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "text='The part was sooo fun :D #superfun'\n",
    "twtkn=TweetTokenizer()\n",
    "twtkn.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=brown.words(categories='government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Office', 'of', 'Business', 'Economics', '(', 'OBE', ...]\n"
     ]
    }
   ],
   "source": [
    "print(words[1:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
